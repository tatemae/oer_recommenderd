package edu.usu.cosl.tagclouds;

import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.util.Arrays;
import java.util.Enumeration;
import java.util.HashSet;
import java.util.Vector;

import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermFreqVector;
import org.apache.lucene.search.Hits;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.store.FSDirectory;
import org.apache.solr.core.SolrCore;

import edu.usu.cosl.recommenderd.Base;
import edu.usu.cosl.util.Locales;
import edu.usu.cosl.util.Logger;

public class SubjectAutoGenerator extends Base 
{
	private PreparedStatement pstGetSubjectID;
	private PreparedStatement pstAddSubject;
	private PreparedStatement pstAddEntrySubject;
	private int nNewEntrySubjects;
	
	private void autoGenerateSubjects(HashSet<String> hsSubjects, int nEntryID, int nLanguageID, int nSubjects, IndexReader reader, IndexSearcher searcher)
	{
		try 
		{
			// find the document
			TermQuery query = new TermQuery(new Term("id", "Entry:" + nEntryID));
		    Hits hits = searcher.search(query);
		    if (hits.length() > 0) 
		    {
				// get its unstemmed terms
			    int nDocID = hits.id(0);
	    		TermFreqVector tfv = reader.getTermFreqVector(nDocID, "tag");
	    	    if (tfv != null)
	    	    {
		    	    String[] asTerms = tfv.getTerms();
		    	    int[] anFrequencies = tfv.getTermFrequencies();
		    	    TermFrequency[] atf = new TermFrequency[asTerms.length];
	    	    	for (int nTerm = 0; nTerm < asTerms.length; nTerm++) {
	    	    		atf[nTerm] = new TermFrequency(asTerms[nTerm], anFrequencies[nTerm]);
	    	    	}
	    	    	Arrays.sort(atf);

	    	    	for (int nTerm = 0; nTerm < asTerms.length && nSubjects < 5 && atf[nTerm].nFrequency > 2; nTerm++)
	    	    	{
	    	    		nSubjects += addEntrySubject(hsSubjects, nEntryID, nLanguageID, atf[nTerm].sTerm);
	    	    	}
	    	    }
		    }
		} catch (Exception e) {
			Logger.error("autoGenerateSubjects-error: ", e);
		}
	}
	
	private int addEntrySubject(HashSet<String> hsSubjects, int nEntryID, int nLanguageID, String sSubject) throws SQLException
	{
		int nAddedSubjects = 0;
		
		// TODO: use the version of this method that takes a locale
		sSubject = sSubject.toLowerCase();
		if (sSubject.length() > 0)
		{
			String[] asSubjects = sSubject.split("--|[:;,\\)(/\".]");
			for (int nSubject = 0; nSubject < asSubjects.length; nSubject++)
			{
				String sNormalizedSubject = asSubjects[nSubject].trim();
				if (sNormalizedSubject.length() > 0 && !hsSubjects.contains(sNormalizedSubject)) {
					pstAddEntrySubject.setInt(1, getSubjectID(sNormalizedSubject));
					pstAddEntrySubject.setInt(2, nLanguageID);
					pstAddEntrySubject.setInt(3, nEntryID);
					pstAddEntrySubject.addBatch();
					nNewEntrySubjects++;
					if (nNewEntrySubjects > 100) {
						try {
							pstAddEntrySubject.executeBatch();
						}catch(Exception e) {
							Logger.error("Error adding entry subjects: ", e);
						}
						nNewEntrySubjects = 0;
					}
					nAddedSubjects++;
				}
			}
		}
		return nAddedSubjects;
	}
	
	private int getSubjectID(String sSubject) throws SQLException
	{
		// set up the prepared statement
		pstGetSubjectID.setString(1, sSubject);
		
		// do the query
		ResultSet rs = pstGetSubjectID.executeQuery();
		
		// if the subject isn't already in the database, add it now
		int nSubjectID = 0;
		if (!rs.next()) nSubjectID = addSubject(sSubject);
		
		// return the subject's id
		else nSubjectID = rs.getInt(1);

		rs.close();
		return nSubjectID;
	}
	
	private int addSubject(String sSubject) throws SQLException
	{
		pstAddSubject.setString(1, sSubject);
		pstAddSubject.executeUpdate();
		return getLastID(pstAddSubject);
	}
	
	private void autoGenerateSubjects() throws Exception
	{
		Logger.status("==========================================================Auto Generate Subjects");
		Logger.status("Auto generating subjects - begin");
	
		createAnalyzers();
		createIndexReaders();
		createIndexSearchers();
		
		cn = getConnection();
		PreparedStatement pstNukeOldAutoSubjects = cn.prepareStatement("DELETE FROM entries_subjects WHERE entry_id = ? AND autogenerated = true");
		PreparedStatement psGetEntrySubjects = cn.prepareStatement("SELECT subjects.name FROM entries_subjects INNER JOIN subjects ON entries_subjects.subject_id = subjects.id WHERE entries_subjects.entry_id = ? LIMIT 5");
		pstGetSubjectID = cn.prepareStatement("SELECT id FROM subjects WHERE name = ?");
		pstAddSubject = cn.prepareStatement("INSERT INTO subjects (name) VALUES (?)");
		pstAddEntrySubject = cn.prepareStatement("INSERT INTO entries_subjects (subject_id, language_id, entry_id, autogenerated) VALUES (?, ?, ?, true)");
		nNewEntrySubjects = 0;
		
		// loop through each of the indexes (languages)
		for (Enumeration<SolrCore> eCores = vCores.elements(); eCores.hasMoreElements();) 
		{
			// get the core
			SolrCore core = eCores.nextElement();
			String sLanguageCode = core.getName();
			
			// open a reader and searcher on the index 
			IndexReader reader = IndexReader.open(FSDirectory.getDirectory(core.getIndexDir()));
			IndexSearcher searcher = new IndexSearcher(reader);
			
			// ask the db for the entries that have been updated or added for the language
			int nLanguageID = Locales.getID(sLanguageCode);
			Vector<Integer> vIDs = getIDsOfEntries("WHERE indexed_at > relevance_calculated_at AND language_id = " + nLanguageID);
			Logger.info("Generating subjects for entries (" + sLanguageCode + "): " + vIDs.size());
			for(Enumeration<Integer> eID = vIDs.elements(); eID.hasMoreElements();)
			{
				int nEntryID = eID.nextElement();

				// delete any autogenerated subjects for this entry 
				pstNukeOldAutoSubjects.setInt(1,nEntryID);
				pstNukeOldAutoSubjects.executeUpdate();

				// for entries that don't have at least 5 subjects, generate some
				psGetEntrySubjects.setInt(1, nEntryID);
				ResultSet rsEntries = psGetEntrySubjects.executeQuery();
				HashSet<String> hsSubjects = new HashSet<String>();
				int nSubjects = 0;
				while (rsEntries.next()) {
					hsSubjects.add(rsEntries.getString(1));
					nSubjects++;
				}
				rsEntries.close();
				if (nSubjects < 5) {
					autoGenerateSubjects(hsSubjects, nEntryID, nLanguageID, nSubjects, reader, searcher);
				}
			}
			// close the index searcher and reader
			searcher.close();
			reader.close();
		}
		psGetEntrySubjects.close();
		pstNukeOldAutoSubjects.close();
		if (nNewEntrySubjects > 0) {
			try {
				pstAddEntrySubject.executeBatch();
			}catch(Exception e) {
				Logger.error("Error adding entry subjects: ", e);
			}
		}
		pstGetSubjectID.close();
		pstAddSubject.close();
		pstAddEntrySubject.close();
		cn.close();
		
		closeIndexSearchers();
		closeIndexReaders();
		closeCores();

		Logger.status("Auto generating subjects - end");
	}

	public static void update() throws Exception
	{
		new SubjectAutoGenerator().autoGenerateSubjects();
	}
	
	public static void main(String[] args) 
	{
		try {
			getLoggerAndDBOptions("recommenderd.properties");
			update();
		} catch (Exception e) {
			Logger.error(e);
		}
		Logger.stopLogging();
	}

}
